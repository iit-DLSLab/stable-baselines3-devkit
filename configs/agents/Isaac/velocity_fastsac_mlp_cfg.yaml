# Reference: https://github.com/amazon-far/holosoma/blob/main/src/holosoma/holosoma/config_values/algo.py
seed: 42
device: "cuda:0"

n_timesteps: 25_000_000
batch_size: 8192
lr_scheduler: "constant"

gamma: 0.97
lr_value: !!float 3e-4
tau: 0.125  # Soft update coefficient (Polyak update)
ent_coef: "auto"
learning_starts: 10
train_freq: !!seq [1, "step"]
gradient_steps: 8
target_update_interval: 1
policy_frequency: 4  # Update actor every N gradient steps
target_entropy_ratio: 0.0  # Scale factor for target entropy (0 = -action_dim)
max_grad_norm: 0.0  # 0 = no gradient clipping
mixed_precision: "bf16"

agent_class: 'fastsac_agent.FastSAC'
policy: 'MlpPolicy'
policy_kwargs:
  actor_hidden_dim: 512
  critic_hidden_dim: 768
  use_layer_norm: true
  log_std_max: 0.0
  log_std_min: -5.0
  use_tanh: true
  n_critics: 2
  num_atoms: 101
  v_min: -20.0
  v_max: 20.0
  # Training parameters
  optimizer_kwargs:
    weight_decay: 0.001
    eps: !!float 1e-08

replay_buffer_class: 'ReplayBuffer'
replay_buffer_kwargs:
  buffer_size: 1024
  cpu_offload: false
  num_workers: 0
  optimize_memory_usage: false

preprocessor_class: 'Gym_2_Sac'
preprocessor_kwargs:
  squash_output: false
  resize_images: !!seq [224, 224]
  drop_images: true
  use_tanh: true
  # prompt_generator: 'FixedPromptGenerator("On the table there is a cube, grasp the cube")'

  # the modes which require normalization procedure
  observation_modes:
    # state: mean_std
    images.camera: min_max
    images.base: min_max
  action_modes:
    # actions: mean_std

  overwrite_stats: false
  stats:  # define fixed normalization stats here using the mapped generic keys.

  # mapping from gym to standard for datasource-parameters disentanglement
  data_key_map:  # env_name to generic_key
    images.base: image1
    images.camera: image2
    state: state
    actions: actions

# ... for the RL algorithm configuration of Isaac, `env_cfg` is not present because it is part of the gym env registration. It is specified in the `env_cfg_entry_point` tag.
